# -*- coding: utf-8 -*-
"""practica8FRK.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_zPDLLDcGuC69Vsxk8PsgbbTJeIIgS37

###Modelo de Maquina de soporte vectorial
####	Realizamos un modelo de máquina de soporte vectorial con los siguientes datos iris.csv
####a.	Realizar una descripción de los datos
####b.	Realizar el gráfico de caja respectivo para todas las variables e identificar los outliers
####c.	Redefinir el modelo, realizar el entrenamiento del modelo
####d.	Realizar el testeo y calcular la matriz de confusión.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import math as m
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import datetime
import matplotlib as mpl

from google.colab import files
files.upload()

"""####a. Realizar una descripción de los datos"""

df=pd.read_excel('Estudiantes.xlsx')
df.head()

#Descripción estadística de datos
df.describe()

#Cálculo de la mediana
df.median()

#búsqueda de datos faltantes
sum(df.isnull().values.ravel())

"""b. Realizar el gráfico de caja respectivo para todas las variables e identificar los outliers"""

#Gráfica de cajas para identificar valores outliers(valores que pueden generar ruido en el modelo)
df.boxplot(figsize=(8,6))
print("Gráfico de Caja")
plt.show()

#Identificamos los límites permitidos
lim_superior=np.percentile(df['horas'],75)
lim_inferior=np.percentile(df['horas'],25)
iqr=lim_superior-lim_inferior #aplitud del intervalo
LS=lim_superior+1.5*iqr
LI=lim_inferior-1.5*iqr
print(LI,LS)

min=df['horas'].min()
max=df['horas'].max()
print(min,max)

df.count()  #teniamos 110 valore

#eliminamos los valores outliers
dg=df [df ['horas'] <=LS]
dh=dg [dg ['horas'] >=LI]
dh.count()  #quitamos 2 valores atipicos

dh.boxplot(figsize=(8,6))
print("Gráfico de Caja")
plt.show()

"""c. Redefinir el modelo, realizar el entrenamiento del modelo"""

set(dh.tipo)

colors={"aprueba":"blue", "desaprueba":"red"}
species_color=dh.tipo.map(colors)
fig, ax = plt.subplots(figsize=(6,4))
ax.scatter(dh['antiguedad'], dh['horas'], color=species_color);
ax.set_title("Dispersión aprueba y desaprueba");
plt.show()

from pandas.plotting import scatter_matrix

scatter_matrix(dh, alpha = 0.9, figsize = (12, 12), diagonal = 'false', marker = 'O', color=species_color )
print('Matriz de variables')

"""#paso 2 muestreo"""

from sklearn.model_selection import train_test_split #utilzamos las librerias para entrenar y testear modelos
train, test=train_test_split(dh, test_size=0.20)

#Validamos los tamaños de las muestras
print(train.count())
print(test.count())

#Variables de entrenamiento X (Independientes), Y (Dependientes)
X_train=train[['antiguedad','horas','notas','ingresos']]
Y_train=train['tipo'] #target

#MODELO SVM (Maquina de soporte vectorial)
from sklearn import svm, datasets
from sklearn.svm import SVC
svc=svm.SVC(kernel='linear',C=1.0).fit(X_train,Y_train) #aplicando el modelo

# Vectores soporte
svc.support_vectors_

X_test=test[['antiguedad','horas','notas','ingresos']]
Y_test=test['tipo']

pred_test=svc.predict(X_test)
pred_test

pred_train=svc.predict(X_train)
pred_train

"""d. Realizar el testeo y calcular la matriz de confusión."""

# Accuracy de test del modelo
#matriz de confusion ... precision global
#....testing
sum(pred_test==Y_test)/(Y_test.count())

#matriz de confusion ... precision global
#....train
sum(pred_train==Y_train)/(Y_train.count())

# Accuracy de test del modelo kernel lineal
# ==============================================================================
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(
            y_true    = Y_test,
            y_pred    = pred_test,
            normalize = True
           )
print("")
print(f"La exactitud de la prueba con el kernel lineal es: {100*accuracy}%")

#Otros modelos MSV con otros Kernel
c=1
svc=svm.SVC(kernel='linear',C=c).fit(X_train,Y_train) #kernel lineal
rbf_svc=svm.SVC(kernel='rbf',gamma=0.7, C=c).fit(X_train,Y_train) #kernel Gaussian
poly_svc=svm.SVC(kernel='poly',degree=3, C=c).fit(X_train,Y_train) #kernel polinomial
sigmoid_svc=SVC(kernel='sigmoid', C=c).fit(X_train,Y_train) #kernel sigmoidea

#probemos con el kernel sigmoidea
#vectores de soporte
sigmoid_svc.n_support_

#los vectores de soporte deben ser los menos posibles
sigmoid_svc.support_vectors_

pred_test1=sigmoid_svc.predict(X_test)
pred_test1

pred_train1=sigmoid_svc.predict(X_train)
pred_train1

#matriz de confusion ... precision global
#....train
sum(pred_train1==Y_train)/(Y_train.count())

#matriz de confusion ... precision global
#....testing
sum(pred_test1==Y_test)/(Y_test.count())

# Accuracy de test del modelo kernel sigmoideo
# ==============================================================================
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(
            y_true    = Y_test,
            y_pred    = pred_test1,
            normalize = True
           )
print("")
print(f"La exactitud de la prueba con el kernel sigmoideo es: {100*accuracy}%")

c=1
poly_svc=svm.SVC(kernel='poly',degree=3, C=c).fit(X_train,Y_train) #kernel polinomial

#probemos con el kernel polinomial
#vectores de soporte
poly_svc.n_support_

#los vectores de soporte deben ser los menos posibles
poly_svc.support_vectors_

pred_test2=poly_svc.predict(X_test)
pred_test2

pred_train2=poly_svc.predict(X_train)
pred_train2

#matriz de confusion ... precision global
#....train
sum(pred_train2==Y_train)/(Y_train.count())

#matriz de confusion ... precision global
#....testing
sum(pred_test2==Y_test)/(Y_test.count())

# Exactitud de test del modelo kernel polinomial
# ==============================================================================
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(
            y_true    = Y_test,
            y_pred    = pred_test2,
            normalize = True
           )
print("")
print(f"El accuracy de test es: {100*accuracy}%")